{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTDQanrJ86Vh"
   },
   "source": [
    "# การบ้านครั้งที่ 4: Social Media Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXvbUjnTOV2Y"
   },
   "source": [
    "**จุดมุ่งหมายของการบ้าน**\n",
    "- เข้าใจและสามารถใช้งาน\n",
    "  - String and file processing\n",
    "  - Basic dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLvxhuA0NIzF"
   },
   "source": [
    "\n",
    "\n",
    "##**เริ่มต้น**\n",
    "1. ให้ copy file ไปที่ Google Drive ของนิสิตโดยเลือกเมนู File->Save a copy in Drive\n",
    "2. ไปที่ไฟล์ที่ copy มาแล้วตั้งชื่อไฟล์เป็น HW4_XXXXXXXXXX.ipynb เมื่อ XXXXXXXXXX คือเลขประจำตัวนิสิต\n",
    "\n",
    "## <font color=red>สำคัญ: อ่านตรงนี้ด้วย\n",
    "## ข้อห้าม</font>\n",
    " - ห้าม import ใด ๆ\n",
    " - ฟังก์ชันต้องไม่ print ใด ๆ นอกเหนือจากคำสั่ง\n",
    " - ห้ามเปลี่ยนบรรทัด `def` ของฟังก์ชันที่ให้เขียน\n",
    " - ในกรณีที่ฟังก์ชันมีการคืนค่า ฟังก์ชันต้องคืนข้อมูลและประเภทข้อมูลตามที่กำหนดเท่านั้น\n",
    " - ฟังก์ชันต้องไม่เปลี่ยนแปลงข้อมูลภายในของพารามิเตอร์ที่ได้รับ\n",
    " - บรรทัดแรกของ code cell ที่เขียนต้องขึ้นต้นด้วย `# HW4_Social_Media_Data` ตามที่ให้ไป ห้ามแก้ไขหรือเพิ่มอะไรเข้าไปก่อนหน้า\n",
    " - สามารถเขียนฟังก์ชันตัวเองได้ในพื้นที่ด้านล่างสุดของเซลล์ที่บอกว่า\n",
    " ```\n",
    " # Write your functions here ONLY (If any)\n",
    " ```\n",
    "\n",
    "- <font color=red>ส่อทุจริต</font> เช่น  \n",
    " - ส่งโปรแกรมที่ผู้ส่งไม่สามารถอธิบายได้ว่า ใช้หลักการและทำงานอย่างไร\n",
    "  - หรือ ส่งโปรแกรมที่คล้ายกับโปรแกรมของผู้อื่นมาก ๆ (ไม่ว่าจะเป็นผู้ให้หรือผู้รับ จะตั้งใจหรือไม่ก็ตาม)\n",
    "  - ฉะนั้น\n",
    "    - ให้แน่ใจว่า ไม่ดูโปรแกรมของคนอื่น\n",
    "    - ให้แน่ใจว่า ไม่ได้ให้คนอื่นดูโปรแกรมของตัวเอง\n",
    "\n",
    "- หากพบว่างานที่ส่งส่อทุจริต นิสิตจะได้ $0$ ใน<font color=red>การบ้านครั้งนี้ และการบ้านครั้งก่อนหน้าทั้งหมด</font>\n",
    "- จะตรวจให้คะแนน เมื่อ\n",
    " - แฟ้มที่ส่งครั้งหลังสุดภายในกำหนดส่งใน MyCourseVille เป็นแฟ้มที่ตั้งชื่อตามที่กำหนด และเป็นแฟ้มที่ได้จากการ File->Download->Download .ipynb เท่านั้น (ไม่ใช่แฟ้ม .py แล้วมา rename เป็น .ipynb)\n",
    " - ฟังก์ชันที่เขียนส่งต้องอยู่ใน code cell ที่ให้มาเท่านั้น\n",
    " - ไม่ทำในสิ่งที่ห้ามทำในข้อห้าม\n",
    " - code cell ที่ให้เขียนสามารถทำงานได้ (ไม่มี error)\n",
    " - ให้แน่ใจว่า code ที่ส่งมา ไม่มี syntax error, indentation error หรืออื่น ๆ ที่ทำให้สั่งทำงาน code ไม่ได้ (ถ้ามี ก็ตรวจไม่ได้ ได้ 0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgsq1C6oOkg_"
   },
   "source": [
    "##**การส่งงาน**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7-Ib0uROq3n"
   },
   "source": [
    "1. ส่งไฟล์ในรูปแบบ .ipynb ที่ได้จากการเลือกเมนู File->Download->Download .ipynb ของ Colab และส่งแฟ้ม ipynb นี้ใน MyCourseVille\n",
    "2. ตั้งชื่อไฟล์เป็น HW4_XXXXXXXXX.ipynb เมื่อ XXXXXXXXXX คือ เลขประจำตัวนิสิต\n",
    "3. ส่งแฟ้ม .ipynb กี่ครั้งก็ได้ แต่จะตรวจแฟ้ม .ipynb **แฟ้มล่าสุด ที่ส่งภายในกำหนด** เท่านั้น\n",
    "4. <font color=\"red\">**กำหนดส่ง คือ ก่อน 23:59 น. ของพุธที่ 27 มีนาคม 2567**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHC4vTRPWZtO"
   },
   "source": [
    "## CSV File\n",
    "Comma-separated values หรือ CSV เป็นรูปแบบไฟล์ข้อความที่คั่นด้วยเครื่องหมาย comma (,) ซึ่งสามารถใช้แสดงข้อมูลในรูปแบบตารางได้\n",
    "\n",
    "* ตัวอย่างข้อมูลด้านล่างเป็นข้อมูลการโพสต์ข้อความทางโซเชียลมีเดียหลากหลายช่องทาง ในช่วงเวลาต่าง ๆ จากหลากหลายประเทศ\n",
    "* ทดลองรันเซลล์ด้านล่าง จะดาวน์โหลดไฟล์มาไว้ใน colab ของเรา\n",
    "* หรือจะดาวน์โหลดจากลิ้งค์นี้ก็ได้ https://drive.google.com/file/d/1N_6buJnQp6M-dQdaC1hVPPX5XDWizjNp/view?usp=share_link\n",
    "* อ้างอิงข้อมูลจาก Social Media Sentiments Analysis Dataset บน Kaggle โดยมีการปรับข้อมูลให้เหมาะกับโจทย์ในการบ้านนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ibgkZGdnY4SH"
   },
   "outputs": [],
   "source": [
    "# !wget https://drive.google.com/uc?id=1N_6buJnQp6M-dQdaC1hVPPX5XDWizjNp -O social_media_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C37ZR_29ceFj"
   },
   "source": [
    "* หากเปิดไฟล์ในโปรแกรม notepad หรือ edittext จะเห็นข้อมูลคั่นด้วย comma (,) ดังแสดงด้านล่าง\n",
    "\n",
    "![CSV file](https://mycourseville-default.s3.ap-southeast-1.amazonaws.com/useruploaded_course_files/2023_2/46110/materials/Screenshot_2567_03_09_at_14.00.36-465640-17099677538211.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hd5H3HcTcnhI"
   },
   "source": [
    "* แต่หากลองเปิดไฟล์ใน Colab (โดยการดับเบิ้ลคลิกที่ไฟล์ **`social_medial_data.csv`** ทางด้านซ้าย) หรือนำไปเปิดใน excel จะเห็นเป็นตารางด้านล่าง\n",
    "\n",
    "![CSV file](https://mycourseville-default.s3.ap-southeast-1.amazonaws.com/useruploaded_course_files/2023_2/46110/materials/Screenshot_2567_03_09_at_13.59.46-465640-17099676757348.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIjf4uXwvJ7-"
   },
   "source": [
    "## งานของคุณ\n",
    "\n",
    "ให้เขียนฟังก์ชัน 6 ฟังก์ชันดังต่อไปนี้ เพื่ออ่านข้อความที่มีการโพสต์บนโซเชียลมีเดียที่รวบรวมอยู่ในชุดข้อมูลที่เตรียมไว้ให้ (social_media_data.csv) และหาคำที่พบบ่อยที่สุด เพื่อใช้ระบุเทรนในช่วงเวลานั้น ๆ\n",
    "\n",
    "* คะแนนฟังก์ชัน 1-5 ฟังก์ชันละ 4 คะแนน ฟังก์ชัน 6 จะเป็น 5 คะแนน\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zBDQiMDIskp"
   },
   "source": [
    "1.   **`social_media_data(file_in)`**\n",
    "\n",
    "รับค่า\n",
    "* **`file_in`**   คือชื่อไฟล์ของข้อมูลโซเชียลมีเดีย เช่น **`social_media_data.csv`**  แต่ไฟล์อาจจะเป็นชื่ออื่นก็ได้ แต่หัวตารางจะเป็นรูปแบบเดียวกันเสมอ ดูตัวอย่างตารางด้านบน\n",
    "\n",
    "คืนค่าเป็น **`Dict`** ของข้อมูลทั้งหมดที่อ่านจากไฟล์ที่มี\n",
    "* ค่า **`key`** เป็นค่าในคอลัมน์ Post_ID ในไฟล์ social_media_data.csv\n",
    "* **`value`** จะเป็นลิสต์ของข้อความ (คอลัมน์ Text), Platform, จำนวน retweet, จำนวน likes, ประเทศ, และปีที่โพสต์ หรือ\n",
    " **`[Text, Platform, Retweets, Likes, Country, Year]`**\n",
    "โดยจำนวน retweet และ likes จะต้องถูกเก็บในรูปแบบจำนวนเต็ม\n",
    "\n",
    "* อย่าลืมที่จะ **`strip()`** แต่ละข้อความที่อ่านมาด้วย\n",
    "* ในกรณีที่เกิด UnicodeDecodeError นิสิตอาจเปิดอ่านไฟล์โดยใช้ Unicode (UTF-8) encoding ดังตัวอย่าง\n",
    "```\n",
    "f = open(file_in, encoding=\"utf-8\")\n",
    "```\n",
    "\n",
    "ตัวอย่างเช่น\n",
    "* **`social_media_data(\"social_media_data.csv\")`**\n",
    "จะคืนค่าเป็น **`Dict`** ที่มีข้อมูลดังนี้\n",
    "```\n",
    "{'0000': ['Enjoying a beautiful day at the park!               #Nature #Park', 'Twitter', 19, 34, 'USA', '2023'],\n",
    "'0001': ['Traffic was terrible this morning.                  #Traffic #Morning', 'Twitter', 6, 18, 'Canada', '2023'],\n",
    "'0002': ['Just finished an amazing workout! 💪                #Fitness #Workout', 'Instagram', 21, 47, 'USA', '2023'],\n",
    "'0003': ['Excited about the upcoming weekend getaway!         #Travel #Adventure', 'Facebook', 9, 17, 'UK', '2023'],\n",
    "...,\n",
    "'0731':['Organizing a virtual talent show during challenging times bringing smiles to classmates' faces!  #VirtualEntertainment #HighSchoolPositivity\", 'Instagram', 24, 51, 'USA', '2020']}\n",
    "```\n",
    "\n",
    "* กรณีไม่มีข้อมูลจะในไฟล์ CSV (มีแต่หัวตาราง) จะคืนค่าเป็น **`Dict`** ว่าง\n",
    "```\n",
    "{}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP1GVJPpIi-I"
   },
   "source": [
    "2.  **`is_stopword(word)`**\n",
    "\n",
    "* ฟังก์ชันตรวจสอบคำหรือ **`word`**  ที่รับเข้ามาว่าเป็น stopword หรือไม่ โดยเทียบกับคำที่เป็น stopword ที่ถูกเก็บไว้ในไฟล์ชื่อ stopwords.txt\n",
    "* Stop words คือคำทั่ว ๆ ไป ที่เราพบบ่อย ๆ ในประโยค หรือ เอกสาร แต่ไม่ค่อยช่วยในการสื่อความหมายนัก เช่น a, an, the, also, just, quite, unless, etc.\n",
    "\n",
    "* คืนค่าบูลลีน ซึ่งจะเป็นจริง เมื่อ **`word`** ที่รับเข้ามาเป็น stopword แต่หากไม่ใช่ จะคืนค่าเป็นเท็จ\n",
    "\n",
    "* หมายเหตุ กรณีคำ stopword ที่มีเครื่องหมายวรรคตอนระหว่างตัวอักษร เช่น can't, isn't, they'll เพื่อให้ง่าย ไม่ได้นำคำเหล่านี้มาคิดเป็น stopword แต่ให้เอาเครื่องหมายวรรคตอนออก และมองเป็นคำเดียว เช่น can't จะเป็นคำว่า cant, isn't เป็นคำว่า isnt, they'll จะเป็นคำกว่า theyll\n",
    "\n",
    "* ตัวอย่างเช่น\n",
    "<table>\n",
    "<tr>\n",
    "  <td>word</td><td>is_stopword(word)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\"Happy\"</td><td>False</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\"birthDay\"</td><td>False</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\"on\"</td><td>True</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\"whiCH\"</td><td>True</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\"Into\"</td><td>True</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\"After\"</td><td>True</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\"AFTER\"</td><td>True</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\"afTEr\"</td><td>True</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\"can't\"</td><td>False</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\"cant\"</td><td>False</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "* ดาวน์โหลด stopwords.txt file ได้จากการรันเซลล์ด้านล่าง หรือจะดาวน์โหลดที่ลิ้งค์นี้ https://drive.google.com/file/d/1iDOFnkVscGQppyoydDyxOCz8AUJd0oUh/view?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ozfbpG0MR5LU"
   },
   "outputs": [],
   "source": [
    "# Download stopwords.txt\n",
    "# !wget https://drive.google.com/uc?id=1iDOFnkVscGQppyoydDyxOCz8AUJd0oUh -O stopwords.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnGiqJ9iI1Lh"
   },
   "source": [
    "3.  **`count_words_from_text(word_count_dict, text)`**\n",
    "\n",
    "ฟังก์ชันนับคำจากข้อความหรือ **`text`** และอัพเดทคำที่นับได้ไปใน  **`Dict`** ที่รับเข้ามา **`word_count_dict`** โดยคำที่นับจะต้องไม่ใช่ Stop words\n",
    "\n",
    "รับค่า\n",
    "* **`word_count_dict`** ซึ่งเป็น **`Dict`** เก็บ key ที่เป็นคำศัพท์ตัวอักษรเล็กทั้งหมด และ value ที่เป็นจำนวนที่นับได้ก่อนหน้า\n",
    "* **`text`** คือข้อความที่จะนำมานับคำและอัพเดทเข้าไปใน **`word_count_dict`**\n",
    "\n",
    "คืนค่า\n",
    "* **`word_count_dict`** การนับคำก่อนหน้าและเพิ่มการนับคำใน **`text`**  เข้าไปด้วย\n",
    "\n",
    "แนะนำเพิ่มเติม\n",
    "* คำที่นับตัวเล็กตัวใหญ่ถือว่าเป็นคำเดียวกัน เช่น Enjoy และ enjoy ถือเป็นคำเดียวกัน\n",
    "* คำที่เป็นพหูพจน์จะถือว่าเป็นคนละคำ เช่น pig และ pigs จะมองเป็นคนละคำ\n",
    "* แนะนำให้เรียกใช้ **`is_stopword(word)`** เพื่อตรวจสอบคำว่าเป็น Stop words หรือไม่ เช่น a เป็น stop word <mark>ไม่</mark>ควรนำมานับด้วย\n",
    "* หากมีการตัดเป็นคำ แนะนำให้ระวังเครื่องหมายวรรคตอนด้วย ได้แก่ .,:;?()[]\"'{}-/\\|_!\n",
    "* คำที่ติด Hashtag (#) คือเป็นคนละคำกับคำที่ไม่ติด # เช่น #Enjoy คือคนละคำกับ Enjoy (จะไม่มี # อยู่เดี่ยว ๆ)\n",
    "* หากเจอคำที่มีเครื่องหมายวรรคตอนคั่นกลาง เพื่อให้ง่ายให้ตัดเครื่องหมายวรรคตอนออก เช่น soul-stirring ให้ใช้เป็นคำศัพท์ว่า soulstirring, Jay-Z ใช้เป็นคำว่า jayz, Can't ใช้เป็นคำว่า cant\n",
    "* ลำดับ key ที่แสดงผลจาก **`word_count_dict`**  ไม่จำเป็นต้องเรียงค่า\n",
    "\n",
    "\n",
    "ตัวอย่างเช่น\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <td>word_count_dict</td>\n",
    "  <td>text</td>\n",
    "  <td>count_words_from_text(word_count_dict, text) -> ลำดับสลับได้</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'aroma': 1, 'market': 1}</td>\n",
    "  <td>\"Hello today! #Happy\"</td>\n",
    "  <td>{'aroma': 1, 'market': 1, 'hello': 1, 'today': 1, '#happy': 1}</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'aroma': 1, 'market': 1}</td>\n",
    "  <td>\"Exploring the local market today, can't wait to share with everyone!\"</td>\n",
    "  <td>{'aroma': 1, 'market': 2, 'exploring': 1, 'local': 1, 'today': 1, 'cant': 1, 'wait': 1, 'share': 1, 'everyone': 1}</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'aroma': 1, 'market': 1}</td>\n",
    "  <td>\"LoVe Aroma THeRapy!! LoVed it LoVe it #AROMA.\"</td>\n",
    "  <td>{'aroma': 2, 'market': 1, 'love': 2, 'therapy': 1, 'loved': 1, '#aroma': 1}</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{}</td>\n",
    "  <td>\"Mary has \"A little Lamb\", LiTTLE Lamb, MARY has a Little cat!! #lamb #cat\"</td>\n",
    "  <td>{'mary': 2, 'little': 3, 'lamb': 2, 'cat': 1, '#lamb': 1, '#cat': 1}</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{}</td>\n",
    "  <td>\"Mary has A lot of Lambs, a little lamb.\"</td>\n",
    "  <td>{'mary': 1, 'lot': 1, 'lambs': 1, 'little': 1, 'lamb': 1}</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'mary': 2, 'little': 3}</td>\n",
    "  <td> \"Twinkle twinkle 'little' star..... How I wonder what you are.\"</td>\n",
    "  <td>{'mary': 2, 'little': 4, 'twinkle': 2, 'star': 1, 'wonder': 1}</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSNkn5JMJEhl"
   },
   "source": [
    "4.  **`count_words_from_data_dict(data_dict, year, country, platform)`**\n",
    "\n",
    "ฟังก์ชันที่นับจำนวนคำจาก\n",
    "* **`data_dict`** ที่เก็บข้อมูลในรูปแบบ **`Dict`** ที่มี **`key`**  เป็น **`Post_ID`** และ **`value`** จะเป็นลิสต์ของข้อความ (คอลัมน์ Text), Platform, จำนวน retweet, จำนวน likes, ประเทศ, และปีที่โพสต์ หรือ\n",
    " **`[Text, Platform, Retweets, Likes, country, Year]`**\n",
    "โดยจำนวน retweet และ likes จะต้องถูกเก็บในรูปแบบจำนวนเต็ม\n",
    "* **`year`** ใส่เป็นข้อความระบุปีใดปีหนึ่ง เช่น 2023 แต่อาจจะใส่ค่า 'all' ได้ด้วยหมายถึงพิจารณาข้อมูลจากทุก ๆ ปี\n",
    "* **`country`** ใส่เป็นชื่อประเทศใดประเทศหนึ่ง เช่น USA แต่อาจจะใส่ค่า 'all' ได้ด้วยหมายถึงพิจารณาข้อมูลจากทุก ๆ ประเทศ\n",
    "* **`platform`** ใส่เป็นชื่อแพลตฟอร์มใดประเทศหนึ่ง เช่น Facebook แต่อาจจะใส่ค่า 'all' ได้ด้วยหมายถึงพิจารณาข้อมูลจากทุก ๆ แพลตฟอร์ม\n",
    "\n",
    "คืนค่าเป็น **`Dict`** ที่นับคำทุกคำในข้อมูลตามปี ประเทศ และแพลตฟอร์มที่กำหนด\n",
    "\n",
    "เพิ่มเติม\n",
    "* สามารถเรียกใช้ **`count_words_from_text(word_count_dict, text)`**\n",
    "* ต้องพิมพ์ตัวอักษรตัวเล็กตัวใหญ่ให้ถูกต้องสำหรับ year, country, และ platform เช่น ถ้าพิมพ์ <mark>J</mark>apan เป็น <mark>j</mark>apan จะไม่มีข้อมูลแสดงออกมา (เพราะข้อมูลมีแต่ <mark>J</mark>apan)\n",
    "\n",
    "ตัวอย่างเช่น\n",
    "* **`data_dict`**  จากฟังก์ชัน\n",
    "  * **`data_dict = social_media_data(\"social_media_data.csv\")`** จะได้ค่าเป็น\n",
    "  ```\n",
    "{'0000': ['enjoying a beautiful day at the park!               #nature #park', 'Twitter', 19, 34, 'USA', '2023'],\n",
    "'0001': ['traffic was terrible this morning.                  #traffic #morning', 'Twitter', 6, 18, 'Canada', '2023'],\n",
    "'0002': ['just finished an amazing workout! 💪                #fitness #workout', 'Instagram', 21, 47, 'USA', '2023'],\n",
    "'0003': ['excited about the upcoming weekend getaway!         #travel #adventure', 'Facebook', 9, 17, 'UK', '2023'],\n",
    "...,\n",
    "'0731':['\"organizing a virtual talent show during challenging times bringing smiles to classmates' faces!  #virtualentertainment #highschoolpositivity\", 'Instagram', 24, 51, 'USA', '2020']}\n",
    "```\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <td>year</td><td>country</td><td>platform</td><td>count_words_from_data_dict(data_dict, year, country, platform)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>'all'</td><td>'all'</td><td>'all'</td><td>{'enjoying': 5, 'beautiful': 4, 'day': 26, 'park': 3, ... } (จำนวน 3446 คำ) </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>'2023'</td><td>'USA'</td><td>'Facebook'</td><td>{'reflecting': 1, 'past': 1, 'looking': 1, 'ahead': 1, '#reflection': 1, ... } (จำนวน 313 คำ) </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>'all'</td><td>'Thailand'</td><td>'all'</td><td>{'heart': 1, 'bustling': 1, 'market': 1, 'street': 1, 'food': 1, 'connoisseur': 1, 'indulges': 1, 'culinary': 1, 'adventure': 1, 'savoring': 1, 'diverse': 1, 'flavors': 1, 'aromas': 1, '#culinaryadventure': 1, '#streetfooddelights': 1}\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>'2023'</td><td>'Thailand'</td><td>'all'</td><td>{}\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>'2020'</td><td>'Japan'</td><td>'Twitter'</td><td>{'avoiding': 1, 'shards': 1, 'shattered': 1, 'dreams': 1, 'walking': 1, 'tightrope': 1, 'resilience': 1, '#resilience': 1, '#tightropewalk': 1}\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>'2020'</td><td>'<mark>j</mark>apan'</td><td>'<mark>t</mark>witter'</td><td>{}\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xZOmztQI75Z"
   },
   "source": [
    "5. **`top_k_words(word_count_dict, k)`**\n",
    "คืนค่าลิสต์ของคำที่มีจำนวนมากที่สุด k จำนวน <mark>เรียงจากจำนวนที่ปรากฏมากที่สุดไปน้อยที่สุด\n",
    "หากมีจำนวนเท่ากันจะเรียงลำดับตามตัวอักษร </mark>\n",
    "\n",
    "รับค่า\n",
    "* **`word_count_dict`** เป็น **`Dict`** ที่เก็บคำและจำนวนการปรากฏของแต่ละคำ\n",
    "* **`k`** จะเป็นอันดับสูงสุด k อันดับ\n",
    "\n",
    "การคืนค่า\n",
    "* คืนลิสต์ที่เรียงลำดับจากคำที่มีจำนวนมากสุดไปน้อยสุด แต่หากมีจำนวนเท่ากันให้เรียงคำตามลำดับตัวอักษรตามพจนานุกรม\n",
    "  * แต่หากอันดับสูงสุดมีมากกว่า k ค่า เช่น ต้องการ 3 คำลำดับสูงสุด ใน **`Dict`**  ตัวอย่างด้านล่าง มีอันดับ 2 ถึง 4 คำ ก็จะคืนลิสต์ของคำที่ซ้ำอันดับที่ 2 ทั้งหมด\n",
    "```\n",
    " {'dreams':15,'like':10,'feeling':10,'journey':10,'sky':10,'challenges':9,'day':9,'new':9,'world':9}\n",
    " ```\n",
    "    * จะได้ผลลัพธ์เป็น **`['dreams', 'feeling', 'journey', 'like', 'sky']`** ลำดับที่ 2 ซ้ำ 4 คำ จึงแสดงผลทั้งหมดเลย\n",
    "  * หากอันดับสูงสุดที่ต้องการมีมากกว่าคำที่มี ใหคืนลิสต์คำเท่าที่มี เรียงลำดับตามพจนานุกรม\n",
    "  \n",
    "ตัวอย่างเช่น\n",
    "<table>\n",
    "<tr>\n",
    "  <td>word_count_dict</td>\n",
    "  <td>k</td>\n",
    "  <td>top_k_words(word_count_dict, k)</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "  <td>{'new':43,'like':27,'day':26,'feeling':26,'dreams':25,'heart':24,'laughter':24,'joy':23,'night':23,'life':22}</td><td>5</td>\n",
    "  <td>['new', 'like', 'day', 'feeling', 'dreams']</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'new':43,'like':27,'day':26,'feeling':26,'dreams':25,'heart':24,'laughter':24,'joy':23,'night':23,'life':22}</td><td>3</td>\n",
    "  <td>['new', 'like', 'day', 'feeling']</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'heart': 1, 'food': 1, 'diverse': 1, 'flavors': 1, 'aromas': 1, '#culinaryadventure': 1, '#streetfooddelights': 1}<td>5</td>\n",
    "  <td>['#culinaryadventure', '#streetfooddelights', 'aromas', 'diverse', 'flavors', 'food', 'heart']</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'heart': 1, 'food': 1, 'diverse': 1, 'flavors': 1, 'aromas': 1, '#culinaryadventure': 1, '#streetfooddelights': 1}<td>3</td>\n",
    "  <td>['#culinaryadventure', '#streetfooddelights', 'aromas', 'diverse', 'flavors', 'food', 'heart']</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'market': 1, 'aroma': 1}<td>5</td>\n",
    "  <td>['aroma', 'market']</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'market': 1, 'aroma': 1}<td>3</td>\n",
    "  <td>['aroma', 'market']</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'aroma': 2, 'market': 1, 'love': 2, 'therapy': 1, 'loved': 1, '#aroma': 1}<td>5</td>\n",
    "  <td>['aroma', 'love', '#aroma', 'loved', 'market', 'therapy']</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>{'aroma': 2, 'market': 1, 'love': 2, 'therapy': 1, 'loved': 1, '#aroma': 1}<td>3</td>\n",
    "  <td>['aroma', 'love', '#aroma', 'loved', 'market', 'therapy']</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "393bjIKfJI79"
   },
   "source": [
    "6.  **count_word_summary(file_in, file_out, k, year, country, platform)**\n",
    "\n",
    "ฟังก์ชันที่อ่านข้อมูลในไฟล์ นับจำนวนคำและเขียนสรุปคำที่ปรากฏบ่อยที่สุด k จำนวน ใน ปี ประเทศ และแพลตฟอร์มที่กำหนด\n",
    "\n",
    "รับค่า\n",
    "* ชื่อไฟล์ **`file_in`** ที่เป็นไฟล์ CSV ที่มีหัวตารางเหมือนไฟล์ **`social_medial_data.csv`**\n",
    "* **`file_out`** ชื่อไฟล์ output (เป็น .txt) ที่จะสรุปคำที่ปรากฏบ่อยสุด จะเป็นอันดับสูงสุด **`k`** คำ ดูรูปแบบการเขียนในตัวอย่าง (ดุเพิ่มเติมเกี่ยวกับ **`k`**ในฟังก์ชัน 5.)\n",
    "* **`year`** ใส่เป็นข้อความระบุปีใดปีหนึ่ง เช่น 2023 แต่อาจจะใส่ค่า 'all' ได้ด้วยหมายถึงพิจารณาข้อมูลจากทุก ๆ ปี\n",
    "* **`country`** ใส่เป็นชื่อประเทศใดประเทศหนึ่ง เช่น USA แต่อาจจะใส่ค่า 'all' ได้ด้วยหมายถึงพิจารณาข้อมูลจากทุก ๆ ประเทศ\n",
    "* **`platform`** ใส่เป็นชื่อแพลตฟอร์มใดประเทศหนึ่ง เช่น Facebook แต่อาจจะใส่ค่า 'all' ได้ด้วยหมายถึงพิจารณาข้อมูลจากทุก ๆ แพลตฟอร์ม\n",
    "\n",
    "<mark>ไม่มีการคืนค่า</mark>\n",
    "\n",
    "แนะนำเพิ่มเติม\n",
    "* แนะนำให้ใช้ฟังก์ชัน 1-5 ก่อนจะนำมาสร้างไฟล์สรุป\n",
    "* ต้องพิมพ์ตัวอักษรตัวเล็กตัวใหญ่ให้ถูกต้องสำหรับ year, country, และ platform เช่น ถ้าพิมพ์ <mark>J</mark>apan เป็น <mark>j</mark>apan จะแสดงผลในไฟล์ **`file_out`** ว่า No data(เพราะข้อมูลมีแต่ <mark>J</mark>apan)\n",
    "\n",
    "ตัวอย่างเช่น\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <td>file_in</td><td>file_out</td><td>k</td><td>year</td><td>country</td><td>platform</td><td>ข้อมูลใน file_out</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>social_medial_data.csv</td><td>summary.txt</td><td>5</td><td>'all'</td><td>'all'</td><td>'all'</td>\n",
    "  <td>new:43</br>like:27</br>day:26</br>feeling:26</br>dreams:25</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>social_medial_data.csv</td><td>summary.txt</td><td>3</td><td>'all'</td><td>'all'</td><td>'all'</td>\n",
    "  <td>new:43</br>like:27</br>day:26</br>feeling:26</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>social_medial_data.csv</td><td>summary.txt</td><td>5</td><td>'2023'</td><td>'USA'</td><td>'Facebook'</td>\n",
    "  <td>art:4</br>every:3</br>experience:3</br>exploring:3</br>local:3</br>love:3</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>social_medial_data.csv</td><td>summary.txt</td><td>3</td><td>'2023'</td><td>'USA'</td><td>'Facebook'</td>\n",
    "  <td>art:4</br>every:3</br>experience:3</br>exploring:3</br>local:3</br>love:3</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>social_medial_data.csv</td><td>summary.txt</td><td>5</td><td>'all'</td><td>'Thailand'</td><td>'all'</td>\n",
    "  <td>#culinaryadventure:1</br>#streetfooddelights:1</br>adventure:1</br>aromas:1</br>bustling:1</br>connoisseur:1</br>culinary:1</br>diverse:1\n",
    "  </br>flavors:1\n",
    "  </br>food:1\n",
    "  </br>heart:1\n",
    "  </br>indulges:1\n",
    "  </br>market:1\n",
    "  </br>savoring:1\n",
    "  </br>street:1\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>social_medial_data.csv</td><td>summary.txt</td><td>3</td><td>'2023'</td><td>'Thailand'</td><td>'all'</td>\n",
    "  <td>No data\n",
    "  </td>\n",
    "  </tr>\n",
    "<tr>\n",
    "  <td>social_medial_data.csv</td><td>summary.txt</td><td>5</td><td>'2023'</td><td>'UK'</td><td>'Instagram'</td>\n",
    "  <td>new:7</br>adventure:4</br>friends:4</br>art:3</br>day:3</br>magic:3</br>weekend:3</br>wine:3\n",
    "  </br>years:3\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>social_medial_data.csv</td><td>summary.txt</td><td>3</td><td>'all'</td><td>'India'</td><td>'all'</td>\n",
    "  <td>day:5</br>new:5</br>painting:5</br>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>social_medial_data.csv</td><td>summary.txt</td><td>5</td><td>'all'</td><td>'India'</td><td>'all'</td>\n",
    "  <td>day:5</br>new:5</br>painting:5\n",
    "  </br>#gratitude:4\n",
    "  </br>#hopeful:4\n",
    "  </br>dreams:4\n",
    "  </br>hopeful:4\n",
    "  </br>life:4\n",
    "  </br>optimism:4\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "32TQlQREdOVp"
   },
   "outputs": [],
   "source": [
    "# HW4_Social_Media_Data\n",
    "\n",
    "# ให้ลบบรรทัด pass แล้วแทนด้วยโค้ดของนิสิต\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def social_media_data(file_in):\n",
    "    d = dict()\n",
    "    with open(file_in, \"r\", encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        Post_ID, Text, _, _, _, Platform, Retweets, Likes, Country, Year, _, _, _ = line.strip().split(',')\n",
    "        d[Post_ID] = [Text.strip(),\n",
    "                      Platform.strip(),\n",
    "                      int(Retweets),\n",
    "                      int(Likes),\n",
    "                      Country.strip(),\n",
    "                      Year.strip()\n",
    "                      ]\n",
    "    return d\n",
    "\n",
    "\n",
    "def is_stopword(word):\n",
    "    with open(\"stopwords.txt\", 'r', encoding='utf-8') as f:\n",
    "        line = f.readline()\n",
    "        s = set(i.strip() for i in line.strip().split(','))\n",
    "        return word.lower().strip() in s\n",
    "\n",
    "\n",
    "def count_words_from_text(word_count_dict, text):\n",
    "    t = re.sub('[.,:;?()\\[\\]\"\\{\\}/|_!\\'-]', '', text.lower().strip()).split()\n",
    "    for i in t:\n",
    "        if not is_stopword(i):\n",
    "            word_count_dict[i] = word_count_dict.get(i, 0) + 1\n",
    "    return word_count_dict\n",
    "\n",
    "\n",
    "def count_words_from_data_dict(data_dict, year, country, platform):\n",
    "    d = dict()\n",
    "    for v in data_dict.values():\n",
    "        t, p, _, _, c, y = v\n",
    "        if (year == 'all' or year == y) and (country == 'all' or country == c) and (platform == 'all' or platform == p):\n",
    "            count_words_from_text(d, t)\n",
    "    return d\n",
    "\n",
    "\n",
    "def top_k_words(word_count_dict, k):\n",
    "    l = [[v, k] for v, k in word_count_dict.items()]\n",
    "    l = sorted(sorted(l, key=lambda x: x[0]), key=lambda x: -x[1])\n",
    "    r = [i for i, _ in l[:k]]\n",
    "\n",
    "    if len(r) < k:\n",
    "        return r\n",
    "    for i, j in l[k:]:\n",
    "        if j != l[k-1][1]:\n",
    "            break\n",
    "        r.append(i)\n",
    "    return r\n",
    "\n",
    "\n",
    "def count_word_summary(file_in, file_out, k, year, country, platform):\n",
    "    data_dict = social_media_data(file_in)\n",
    "    word_count_dict = count_words_from_data_dict(data_dict, year,\n",
    "                                                 country, platform)\n",
    "    l = top_k_words(word_count_dict, k)\n",
    "    with open(file_out, \"w\", encoding='utf-8') as f:\n",
    "        if len(l) == 0:\n",
    "            f.write('No data')\n",
    "            return\n",
    "        for i in l:\n",
    "            f.write(i+\":\"+str(word_count_dict[i])+\"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ofeef8wy_qxf"
   },
   "source": [
    "## **กรณีทดสอบ**\n",
    "\n",
    "1. กรณีทดสอบไหนที่ run แล้วผ่าน จะเห็นข้อความ `... ok`\n",
    "\n",
    "เช่น\n",
    "```\n",
    "test_1_social_media_data (__main__.TestHW4) ... ok\n",
    "test_2_is_stopword (__main__.TestHW4) ... ok\n",
    "test_3_count_words_from_text (__main__.TestHW4) ... ok\n",
    "test_4_count_words_from_data_dict (__main__.TestHW4) ... ok\n",
    "test_5_top_k_words (__main__.TestHW4) ... ok\n",
    "test_6_count_word_summary (__main__.TestHW4) ... ok\n",
    "```\n",
    "หมายถึงทั้ง 6 ฟังก์ชันทำงานได้ถูกต้อง\n",
    "\n",
    "\n",
    "2. กรณีทดสอบฟังก์ชันใดที่รันแล้ว เห็นข้อความ `... skipped` แสดงว่ายังไม่ได้เขียนฟังก์ชันนั้น เช่น\n",
    "\n",
    "```\n",
    "test_3_count_words_from_text (__main__.TestHW4) ... skipped '\"count_words_from_text()\" is not defined or not implemented'\n",
    "```\n",
    "\n",
    "แสดงว่ายังไม่ได้เขียนฟังก์ชันที่ 3 ฟังก์ชัน count_words_from_text()\n",
    "\n",
    "\n",
    "\n",
    "3. กรณีหากฟังก์ชั่นใด<mark>ได้ผลไม่ถูกต้อง</mark> run แล้วจะเจอข้อความดังตัวอย่างข้างล่างนี้\n",
    "เคสนั้น ๆ จะ<mark>ไม่มีคำว่า ok และ skipped</mark>\n",
    "```\n",
    "test_6_count_word_summary (__main__.TestHW4) ...\n",
    "```\n",
    "และมีรายละเอียด\n",
    "\n",
    "```\n",
    "======================================================================\n",
    "FAIL: test_6_count_word_summary (__main__.TestHW4) (i=1)\n",
    "----------------------------------------------------------------------\n",
    "Traceback (most recent call last):\n",
    "  File \"/hw4_testcases.py\", line 205, in test_6_count_word_summary\n",
    "    self.assertEqual(\"\".join(f.readlines()).strip(), test_case['expected'])\n",
    "AssertionError: 'new:43\\nlike:27\\nday:26\\nfeeling:26' != 'new:43\\nlike:27\\nday:26\\nfeeling:27'\n",
    "  new:43\n",
    "  like:27\n",
    "  day:26\n",
    "- feeling:26?          ^\n",
    "+ feeling:27?          ^\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "หมายถึง ใน `test_6_count_word_summary` .ให้ผลลัพธ์ไม่ตรงกับที่ควรจะเป็นในกรณีทดสอบย่อยลำดับที่ 2 (ดูตรง i=1 ลำดับแรกเริ่มที่ i = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sFUo5g9AXhr"
   },
   "source": [
    "### Download files ที่ต้องใช้ในการทดสอบด้านล่างก่อน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Sv1oFeHlAa2s"
   },
   "outputs": [],
   "source": [
    "# !wget https://drive.google.com/uc?id=1N_6buJnQp6M-dQdaC1hVPPX5XDWizjNp -O social_media_data.csv\n",
    "# !wget https://drive.google.com/uc?id=1sHkrgk-HL1EcO1ICXIEheTv7mENaoiSX -O empty_data.csv\n",
    "# !wget https://drive.google.com/uc?id=1CqL0a52Tc1UmJyCtd3rKG6CllmEnCBwW -O 4_1.txt\n",
    "# !wget https://drive.google.com/uc?id=1TDTtQF5FgzqYJs5HprnXRAJsXzqXMJ4y -O 4_2.txt\n",
    "# !wget https://drive.google.com/uc?id=1xTJOuNmJclFd3P28hS__FkxNL02CQhfz -O 1_1.txt\n",
    "# !wget https://drive.google.com/uc?id=1iDOFnkVscGQppyoydDyxOCz8AUJd0oUh -O stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown 'https://drive.google.com/uc?id=1N_6buJnQp6M-dQdaC1hVPPX5XDWizjNp' -O social_media_data.csv\n",
    "# !gdown 'https://drive.google.com/uc?id=1sHkrgk-HL1EcO1ICXIEheTv7mENaoiSX' -O empty_data.csv\n",
    "# !gdown 'https://drive.google.com/uc?id=1CqL0a52Tc1UmJyCtd3rKG6CllmEnCBwW' -O 4_1.txt\n",
    "# !gdown 'https://drive.google.com/uc?id=1TDTtQF5FgzqYJs5HprnXRAJsXzqXMJ4y' -O 4_2.txt\n",
    "# !gdown 'https://drive.google.com/uc?id=1xTJOuNmJclFd3P28hS__FkxNL02CQhfz' -O 1_1.txt\n",
    "# !gdown 'https://drive.google.com/uc?id=1iDOFnkVscGQppyoydDyxOCz8AUJd0oUh' -O stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtlurKcT_tfA",
    "outputId": "cab870af-504b-4397-fed3-5b755d52451e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_1_social_media_data (__main__.TestHW4.test_1_social_media_data) ... ok\n",
      "test_2_is_stopword (__main__.TestHW4.test_2_is_stopword) ... ok\n",
      "test_3_count_words_from_text (__main__.TestHW4.test_3_count_words_from_text) ... ok\n",
      "test_4_count_words_from_data_dict (__main__.TestHW4.test_4_count_words_from_data_dict) ... ok\n",
      "test_5_top_k_words (__main__.TestHW4.test_5_top_k_words) ... ok\n",
      "test_6_count_word_summary (__main__.TestHW4.test_6_count_word_summary) ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 1.592s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x76d4b0700ed0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "def is_function_defined(func_name):\n",
    "    return func_name in globals()\n",
    "\n",
    "def skip_if_not_implemented(func_name):\n",
    "    def decorator(test_func):\n",
    "        if not is_function_defined(func_name):\n",
    "            return unittest.skip(\"\\\"\" + func_name + \"()\\\" is not defined or not implemented\")(test_func)\n",
    "        return test_func\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class TestHW4(unittest.TestCase):\n",
    "\n",
    "    @skip_if_not_implemented('social_media_data')\n",
    "    def test_1_social_media_data(self):\n",
    "        test_case = {'args':'social_media_data.csv', 'expected':'1_1.txt'}\n",
    "        result = social_media_data(test_case['args'])\n",
    "        fsol = open(test_case['expected'],'r',encoding=\"utf-8\")\n",
    "        self.assertEqual(str(sorted(result.items())), \"\".join(fsol.readlines()))\n",
    "        fsol.close()\n",
    "\n",
    "        test_case = {'args':'empty_data.csv', 'expected': {}}\n",
    "        result = social_media_data(test_case['args'])\n",
    "        self.assertEqual(result, test_case['expected'])\n",
    "\n",
    "\n",
    "    @skip_if_not_implemented('is_stopword')\n",
    "    def test_2_is_stopword(self):\n",
    "        test_cases = [\n",
    "            {'args':\"Happy\", 'expected':False},\n",
    "            {'args':\"birthDay\", 'expected':False},\n",
    "            {'args':\"on\", 'expected':True},\n",
    "            {'args':\"whiCH\", 'expected':True},\n",
    "            {'args':\"Into\", 'expected':True},\n",
    "            {'args':\"After\", 'expected':True},\n",
    "            {'args':\"AFTER\", 'expected':True},\n",
    "            {'args':\"afTEr\", 'expected':True},\n",
    "            {'args':\"can't\", 'expected':False},\n",
    "            {'args':\"cant\", 'expected':False}\n",
    "            ]\n",
    "        for i, test_case in enumerate(test_cases):\n",
    "            with self.subTest(i = i):\n",
    "                result = is_stopword(test_case['args'])\n",
    "                self.assertEqual(result, test_case['expected'])\n",
    "\n",
    "    @skip_if_not_implemented('count_words_from_text')\n",
    "    def test_3_count_words_from_text(self):\n",
    "        test_cases = [\n",
    "            {'args':[{'aroma': 1, 'market': 1},\"Hello today! #Happy\"], 'expected':{'aroma': 1, 'market': 1, 'hello': 1, 'today': 1, '#happy': 1}},\n",
    "            {'args':[{'aroma': 1, 'market': 1},\"Exploring the local market today, can't wait to share with everyone!\"], 'expected':{'aroma': 1, 'market': 2, 'exploring': 1, 'local': 1, 'today': 1, 'cant': 1, 'wait': 1, 'share': 1, 'everyone': 1}},\n",
    "            {'args':[{'aroma': 1, 'market': 1},\"LoVe Aroma THeRapy!! LoVed it LoVe it #AROMA.\"], 'expected':{'aroma': 2, 'market': 1, 'love': 2, 'therapy': 1, 'loved': 1, '#aroma': 1}},\n",
    "            {'args':[{},\"Mary has \\\"A little Lamb\\\", LiTTLE Lamb, MARY has a Little cat!! #lamb #cat\"], 'expected':{'mary': 2, 'little': 3, 'lamb': 2, 'cat': 1, '#lamb': 1, '#cat': 1}},\n",
    "            {'args':[{},\"Mary has A lot of Lambs, a little lamb.\"], 'expected':{'mary': 1, 'lot': 1, 'lambs': 1, 'little': 1, 'lamb': 1}},\n",
    "            {'args':[{'mary': 2, 'little': 3},\"Twinkle twinkle 'little' star..... How I wonder what you are.\"], 'expected':{'mary': 2, 'little': 4, 'twinkle': 2, 'star': 1, 'wonder': 1}},\n",
    "            ]\n",
    "        for i, test_case in enumerate(test_cases):\n",
    "            with self.subTest(i = i):\n",
    "                d,t = test_case['args']\n",
    "                result = count_words_from_text(d,t)\n",
    "                self.assertEqual(result, test_case['expected'])\n",
    "\n",
    "    @skip_if_not_implemented('count_words_from_data_dict')\n",
    "    def test_4_count_words_from_data_dict(self):\n",
    "        test_cases = [\n",
    "            {'args':['all','all','all'], 'expected':'4_1.txt'},\n",
    "            {'args':['2023','USA','Facebook'], 'expected':'4_2.txt'},\n",
    "            {'args':['all','Thailand','all'], 'expected':{'heart': 1, 'bustling': 1, 'market': 1, 'street': 1, 'food': 1, 'connoisseur': 1, 'indulges': 1, 'culinary': 1, 'adventure': 1, 'savoring': 1, 'diverse': 1, 'flavors': 1, 'aromas': 1, '#culinaryadventure': 1, '#streetfooddelights': 1}},\n",
    "            {'args':['2023','Thailand','all'], 'expected':{}},\n",
    "            {'args':['2020','Japan','Twitter'], 'expected':{'avoiding': 1, 'shards': 1, 'shattered': 1, 'dreams': 1, 'walking': 1, 'tightrope': 1, 'resilience': 1, '#resilience': 1, '#tightropewalk': 1}},\n",
    "            {'args':['2020','japan','twitter'], 'expected':{}},\n",
    "            ]\n",
    "        data_dict = social_media_data(\"social_media_data.csv\")\n",
    "        for i, test_case in enumerate(test_cases):\n",
    "            with self.subTest(i = i):\n",
    "                y,c,p = test_case['args']\n",
    "                result = count_words_from_data_dict(data_dict,y,c,p)\n",
    "                if i < 2:\n",
    "                    fsol = open(test_case['expected'],'r',encoding=\"utf-8\")\n",
    "                    self.assertEqual(str(sorted(result.items())), \"\".join(fsol.readlines()))\n",
    "                    fsol.close()\n",
    "                else:\n",
    "                    self.assertEqual(result, test_case['expected'])\n",
    "\n",
    "    @skip_if_not_implemented('top_k_words')\n",
    "    def test_5_top_k_words(self):\n",
    "        test_cases = [\n",
    "            {'args':[{'new':43,'like':27,'day':26,'feeling':26,'dreams':25,'heart':24,'laughter':24,'joy':23,'night':23,'life':22},5], 'expected':['new', 'like', 'day', 'feeling', 'dreams']},\n",
    "            {'args':[{'new':43,'like':27,'day':26,'feeling':26,'dreams':25,'heart':24,'laughter':24,'joy':23,'night':23,'life':22},3], 'expected':['new', 'like', 'day', 'feeling']},\n",
    "            {'args':[{'heart': 1, 'food': 1, 'diverse': 1, 'flavors': 1, 'aromas': 1, '#culinaryadventure': 1, '#streetfooddelights': 1},5], 'expected':['#culinaryadventure', '#streetfooddelights', 'aromas', 'diverse', 'flavors', 'food', 'heart']},\n",
    "            {'args':[{'heart': 1, 'food': 1, 'diverse': 1, 'flavors': 1, 'aromas': 1, '#culinaryadventure': 1, '#streetfooddelights': 1},3], 'expected':['#culinaryadventure', '#streetfooddelights', 'aromas', 'diverse', 'flavors', 'food', 'heart']},\n",
    "            {'args':[{'market': 1, 'aroma': 1},5], 'expected':['aroma', 'market']},\n",
    "            {'args':[{'market': 1, 'aroma': 1},3], 'expected':['aroma', 'market']},\n",
    "            {'args':[{'aroma': 2, 'market': 1, 'love': 2, 'therapy': 1, 'loved': 1, '#aroma': 1},5], 'expected':['aroma', 'love', '#aroma', 'loved', 'market', 'therapy']},\n",
    "            {'args':[{'aroma': 2, 'market': 1, 'love': 2, 'therapy': 1, 'loved': 1, '#aroma': 1},3], 'expected':['aroma', 'love', '#aroma', 'loved', 'market', 'therapy']},\n",
    "            ]\n",
    "        for i, test_case in enumerate(test_cases):\n",
    "            with self.subTest(i = i):\n",
    "                d,k = test_case['args']\n",
    "                result = top_k_words(d,k)\n",
    "                self.assertEqual(result, test_case['expected'])\n",
    "\n",
    "    @skip_if_not_implemented('count_word_summary')\n",
    "    def test_6_count_word_summary(self):\n",
    "        test_cases = [\n",
    "            {'args':['social_media_data.csv','summary.txt',5,'all','all','all'], 'expected':'new:43\\nlike:27\\nday:26\\nfeeling:26\\ndreams:25'},\n",
    "            {'args':['social_media_data.csv','summary2.txt',3,'all','all','all'], 'expected':'new:43\\nlike:27\\nday:26\\nfeeling:26'},\n",
    "            {'args':['social_media_data.csv','summary.txt',5,'2023','USA','Facebook'], 'expected':'art:4\\nevery:3\\nexperience:3\\nexploring:3\\nlocal:3\\nlove:3'},\n",
    "            {'args':['social_media_data.csv','summary2.txt',3,'2023','USA','Facebook'], 'expected':'art:4\\nevery:3\\nexperience:3\\nexploring:3\\nlocal:3\\nlove:3'},\n",
    "            {'args':['social_media_data.csv','summary.txt',5,'all','Thailand','all'], 'expected':'#culinaryadventure:1\\n#streetfooddelights:1\\nadventure:1\\naromas:1\\nbustling:1\\nconnoisseur:1\\nculinary:1\\ndiverse:1\\nflavors:1\\nfood:1\\nheart:1\\nindulges:1\\nmarket:1\\nsavoring:1\\nstreet:1'},\n",
    "            {'args':['social_media_data.csv','summary1.txt',3,'2023','Thailand','all'], 'expected':'No data'},\n",
    "            {'args':['social_media_data.csv','summary2.txt',5,'2023','UK','Instagram'], 'expected':'new:7\\nadventure:4\\nfriends:4\\nart:3\\nday:3\\nmagic:3\\nweekend:3\\nwine:3\\nyears:3'},\n",
    "            {'args':['social_media_data.csv','summary3.txt',3,'all','India','all'], 'expected':'day:5\\nnew:5\\npainting:5'},\n",
    "            {'args':['social_media_data.csv','summary4.txt',5,'all','India','all'], 'expected':'day:5\\nnew:5\\npainting:5\\n#gratitude:4\\n#hopeful:4\\ndreams:4\\nhopeful:4\\nlife:4\\noptimism:4'},\n",
    "\n",
    "            ]\n",
    "        for i, test_case in enumerate(test_cases):\n",
    "            with self.subTest(i = i):\n",
    "                file_in, file_out, k, year, country, platform = test_case['args']\n",
    "                count_word_summary(file_in, file_out, k, year, country, platform)\n",
    "                f = open(file_out,'r',encoding=\"utf-8\")\n",
    "                self.assertEqual(\"\".join(f.readlines()).strip(), test_case['expected'])\n",
    "                f.close()\n",
    "\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
